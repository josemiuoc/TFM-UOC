{"cells":[{"cell_type":"code","source":["!pip install timm"],"metadata":{"id":"25W06d7qjIRj"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W8ftcGkqFVac"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.transforms as transforms\n","import torchvision.models as models\n","import time\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, classification_report\n","import seaborn as sns\n","from torch.utils.data import DataLoader, TensorDataset\n","from tqdm import tqdm\n","import os\n","from PIL import Image\n","from timm import create_model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25702,"status":"ok","timestamp":1715881659311,"user":{"displayName":"José Miguel","userId":"06086994168164684591"},"user_tz":-120},"id":"qzfk-0bfRcxK","outputId":"95a13652-10cb-445b-a02b-776f00e574ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yhB_ni96FIUb"},"outputs":[],"source":["cbisddsm = '/content/drive/MyDrive/cbis-ddsm/'\n","cmmd = '/content/drive/MyDrive/output/'\n","modelsdir = '/content/drive/MyDrive/combined/'\n","imagesEnsemble = '/content/drive/MyDrive/combined/imagesEnsemble'\n","\n","deit = '/content/drive/MyDrive/combined/Deit.pth'\n","densenet201 = '/content/drive/MyDrive/combined/densenet201.pth'\n","inceptionv3full = '/content/drive/MyDrive/combined/inceptionv3m_fulltrained.pth'\n","resnet50 = '/content/drive/MyDrive/combined/resnet50.pth'\n","vgg16bn = '/content/drive/MyDrive/combined/vgg16bn.pth'\n","densenet212 = '/content/drive/MyDrive/combined/densenet121.pth'\n","inceptionv3 = '/content/drive/MyDrive/combined/inceptionv3.pth'\n","efficientnetB0 = '/content/drive/MyDrive/combined/efficientnetB0.pth'\n","EnhancedCNN = '/content/drive/MyDrive/output/models/Combined_EnhancedCNN.pth'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zbh9T_kC-DW1"},"outputs":[],"source":["X_train = torch.load(datasetdir + \"/X_train_balanced.pt\")\n","y_train = torch.load(datasetdir + \"/y_train_balanced.pt\")\n","\n","X_test = torch.load(datasetdir + \"/X_test.pt\")\n","y_test = torch.load(datasetdir + \"/y_test.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":487,"status":"ok","timestamp":1714494573994,"user":{"displayName":"José Miguel","userId":"06086994168164684591"},"user_tz":-120},"id":"W1QekXkAjtpo","outputId":"c1c96366-5b06-46dc-a2c1-6a8022c9d492"},"outputs":[{"output_type":"stream","name":"stdout","text":["X train shape : torch.Size([1318, 3, 224, 224])\n","y train shape : torch.Size([1318])\n","X test shape : torch.Size([378, 3, 224, 224])\n","y test shape : torch.Size([378])\n"]}],"source":["print('X train shape : {}' .format(X_train.shape))\n","print('y train shape : {}' .format(y_train.shape))\n","print('X test shape : {}' .format(X_test.shape))\n","print('y test shape : {}' .format(y_test.shape))"]},{"cell_type":"code","source":["# Necesario para que el modelo entrenado pueda ser cargado, si no, da fallo\n","class EnhancedCNN(nn.Module):\n","    def __init__(self):\n","        super(EnhancedCNN, self).__init__()\n","\n","        # Primera capa\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(32),  # Normalización por lotes\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Dropout(0.3)  # Dropout para reducir el sobreajuste\n","        )\n","\n","        self.conv2 = nn.Sequential(\n","            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Dropout(0.3)\n","        )\n","\n","        self.conv3 = nn.Sequential(\n","            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Dropout(0.3)\n","        )\n","\n","        self.conv4 = nn.Sequential(\n","            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Dropout(0.3)\n","        )\n","\n","        # Clasificador final\n","        self.classifier = nn.Sequential(\n","            nn.Linear(256 * 14 * 14, 256),\n","            nn.BatchNorm1d(256),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(256, 1)\n","        )\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        x = self.conv3(x)\n","        x = self.conv4(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.classifier(x)\n","        return x"],"metadata":{"id":"zrwXR-LXycZv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_model(path):\n","    model.load(path)\n","    model.eval()\n","    return model\n","\n","model_paths = {\n","    'deit': '/content/drive/MyDrive/combined/Deit.pth',\n","    'inceptionv3full': '/content/drive/MyDrive/combined/inceptionv3m_fulltrained.pth',\n","    'resnet50': '/content/drive/MyDrive/combined/resnet50.pth',\n","    'vgg16bn': '/content/drive/MyDrive/combined/vgg16bn.pth',\n","    'densenet121': '/content/drive/MyDrive/combined/densenet121.pth',\n","    'inceptionv3': '/content/drive/MyDrive/combined/inceptionv3.pth',\n","    'efficientnetB0Manual': '/content/drive/MyDrive/combined/efficientnetB0_manual.pth'\n","    'EnhancedCNN' : '/content/drive/MyDrive/output/models/Combined_EnhancedCNN.pth',\n","    'CNN-LCNGCN': '/content/drive/MyDrive/output/models/Combined_CNN_LCN_GCN.pth'\n","}\n","\n","model_classes = {\n","    'resnet50': models.resnet50,\n","    'densenet121': models.densenet121(pretrained=False),\n","    'efficientnetB0Manual': EfficientNetB0(num_classes=2),\n","    'EnhancedCNN': EnhancedCNN(),\n","    'CNN-LCNGCN': EnhancedCNN(),\n","    'densenet121Pesos': models.densenet121(weights='DenseNet121_Weights.DEFAULT')\n","\n","}\n","\n","num_classes = 2\n","loaded_models = {name: load_model(path) for name, path in model_paths.items()}\n","\n","transform = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","def predict(models, image_path, weights=None):\n","    image = Image.open(image_path).convert('RGB')\n","    input_tensor = transform(image).unsqueeze(0)\n","\n","    if weights is None:\n","        weights = {name: 1.0 for name in models.keys()}\n","\n","    total_weight = sum(weights.values())\n","    weights = {name: weight / total_weight for name, weight in weights.items()}\n","\n","    predictions = {}\n","    for name, model in models.items():\n","        with torch.no_grad():\n","            output = model(input_tensor)\n","            predictions[name] = F.softmax(output, dim=1) * weights[name]\n","\n","    final_prediction = sum(predictions.values())\n","    _, predicted_class = torch.max(final_prediction, 1)\n","\n","    return predicted_class.item()\n","\n","image_path = '/content/drive/MyDrive/output/D2-0748_1-1.png'\n","realLabel = 1\n","\n","weights = {\n","    'resnet50': 0.73,\n","    'densenet121': 0.82,\n","    'densenet121Pesos': 0.78,\n","    'efficientnetB0Manual': 0.81,\n","    'EnhancedCNN': 0.83,\n","    'CNN-LCNGCN': 0.83\n","}\n","predicted_class = predict(models, image_path, weights)\n","print(f'Predicted class: {predicted_class}')\n"],"metadata":{"id":"SjrLmJAbUxEJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","\n","        self.features = nn.Sequential(\n","            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )\n","\n","        self.classifier = nn.Sequential(\n","            nn.Linear(128 * 14 * 14, 128),\n","            nn.ReLU(),\n","            nn.Linear(128, 2)\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.classifier(x)\n","        return x"],"metadata":{"id":"NcstH7ndlA_6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict_image(model, image_path, device):\n","    filas = 224\n","    columnas = 224\n","\n","    preprocess = transforms.Compose([\n","        transforms.Resize((filas, columnas)),\n","        transforms.Grayscale(),\n","        transforms.ToTensor(),\n","        transforms.Normalize(0.5, 0.5)\n","    ])\n","\n","    image_path = os.path.join(image_path)\n","    img = Image.open(image_path)\n","    img_tensor = preprocess(img)\n","    img_tensor = img_tensor.unsqueeze(0).to(device)\n","\n","    model_path = '/content/drive/MyDrive/OLD_output/models/CombinedCNN.pth'\n","    model = torch.load(model_path, map_location=device)\n","    model.eval()\n","\n","    with torch.no_grad():\n","        output = model(img_tensor)\n","\n","    _, predicted_class = torch.max(output, 1)\n","    return predicted_class.item()\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","#image_path = '/content/drive/MyDrive/cbis-ddsm/jpeg/1.3.6.1.4.1.9590.100.1.2.245063149211255120613007755642780114172/1-271.jpg' # Debe dar predicción BENIGNO\n","image_path = '/content/drive/MyDrive/output/images/D2-0748_1-1.png' # Debe dar predicción MALIGNO\n","predicted_class = predict_image(CNN().to(device), image_path, device)\n","\n","print(f'Valor de predicción: {predicted_class}')\n","\n","if predicted_class == 0:\n","    print(\"Predicción: BENIGNO\")\n","else:\n","    print(\"Predicción: MALIGNO\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lWUBbv5PkhO6","executionInfo":{"status":"ok","timestamp":1715883691115,"user_tz":-120,"elapsed":215,"user":{"displayName":"José Miguel","userId":"06086994168164684591"}},"outputId":"533618ae-28f3-4482-c65b-2c334ccec206"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Valor de predicción: 1\n","Predicción: MALIGNO\n"]}]},{"cell_type":"code","source":["def load_models(model_paths, device):\n","    models = {}\n","    for name, path in model_paths.items():\n","        model = torch.load(path, map_location=device)\n","        model.eval()\n","        models[name] = model\n","    return models\n","\n","def get_preprocess(num_channels):\n","    filas = 224\n","    columnas = 224\n","\n","    if num_channels == 3:\n","        return transforms.Compose([\n","            transforms.Resize((filas, columnas)),\n","            transforms.Grayscale(num_output_channels=3),\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","        ])\n","    else:\n","        return transforms.Compose([\n","            transforms.Resize((filas, columnas)),\n","            transforms.Grayscale(),\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean=[0.5], std=[0.5])\n","        ])\n","\n","def collective_predict(models, image_path, device, weights):\n","    image_path = os.path.join(image_path)\n","    img = Image.open(image_path).convert('L')\n","\n","    total_weight = sum(weights.values())\n","    weights = {name: weight / total_weight for name, weight in weights.items()}\n","\n","    final_prediction = torch.zeros(1, 2).to(device)\n","\n","    for name, model in models.items():\n","        print(f\"Procesando modelo: {name}\")  # Depuración\n","        try:\n","            first_layer = next(model.parameters())\n","            num_channels = first_layer.shape[1]\n","        except StopIteration:\n","            num_channels = 1\n","\n","        preprocess = get_preprocess(num_channels)\n","        img_tensor = preprocess(img)\n","        img_tensor = img_tensor.unsqueeze(0).to(device)\n","\n","        with torch.no_grad():\n","            output = model(img_tensor)\n","\n","            if isinstance(output, tuple):\n","                output = output[0]\n","\n","            print(f\"Salida del modelo {name}: {output}\")  # Depuración\n","\n","            if output.dim() == 1:\n","                print(f\"Ajustando salida del modelo {name} de {output.shape} a [1, {output.shape[0]}]\")\n","                output = output.unsqueeze(0)\n","\n","\n","            final_prediction += F.softmax(output, dim=1) * weights[name]\n","            print(f\"Salida calculada predictiva: {final_prediction}\"\n","\n","    _, predicted_class = torch.max(final_prediction, 1)\n","    #print(f\"Salida calculada predictiva: {predicted_class.item()}\")  # Depuración\n","    return predicted_class.item()"],"metadata":{"id":"FtDCyL8Spq0b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import transforms\n","from PIL import Image\n","import os\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model_paths = {\n","    'deit': '/content/drive/MyDrive/combined/Deit.pth',\n","    'inceptionv3full': '/content/drive/MyDrive/combined/inceptionv3m_fulltrained.pth',\n","    'resnet50': '/content/drive/MyDrive/combined/resnet50.pth',\n","    'vgg16bn': '/content/drive/MyDrive/combined/vgg16bn.pth',\n","    'densenet121': '/content/drive/MyDrive/combined/densenet121.pth',\n","    'inceptionv3': '/content/drive/MyDrive/combined/inceptionv3.pth',\n","    'efficientnetB0Manual': '/content/drive/MyDrive/combined/efficientnetB0_manual.pth'\n","    'EnhancedCNN' : '/content/drive/MyDrive/output/models/Combined_EnhancedCNN.pth'\n","}\n","\n","weights = { # Pesos según F1-Score para la ponderación de la decisión\n","    'resnet50': 0.73,\n","    'vgg16bn': 0.61,\n","    'densenet121': 0.78,\n","    'inceptionv3': 0.81,\n","    'efficientnetB0Manual': 0.81,\n","    'EnhancedCNN': 0.84\n","}\n","\n","models = load_models(model_paths, device)\n","image_path = '/content/drive/MyDrive/output/images/D2-0748_1-1.png'\n","\n","predicted_class = collective_predict(models, image_path, device, weights)\n","\n","if predicted_class == 0:\n","    print(\"Predicción: BENIGNO\")\n","else:\n","    print(\"Predicción: MALIGNO\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LQMKe1x8rQOJ","executionInfo":{"status":"ok","timestamp":1715886108358,"user_tz":-120,"elapsed":4210,"user":{"displayName":"José Miguel","userId":"06086994168164684591"}},"outputId":"1f760bd4-98f8-47c4-c1b0-d550a54bb86c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Procesando modelo: densenet201\n","Salida del modelo densenet201: tensor([[-0.3641,  0.3768]])\n","Salida calculada predictiva: tensor([[0.1137, 0.2384]])\n","Procesando modelo: inceptionv3full\n","Salida del modelo inceptionv3full: tensor([[ 0.4031, -0.3669]])\n","Salida calculada predictiva: tensor([[0.2003, 0.2786]])\n","Procesando modelo: vgg16bn\n","Salida del modelo vgg16bn: tensor([[-0.3353,  0.3012]])\n","Salida calculada predictiva: tensor([[0.2746, 0.4190]])\n","Procesando modelo: densenet121\n","Salida del modelo densenet121: tensor([[-0.2768,  1.2441]])\n","Salida calculada predictiva: tensor([[0.2854, 0.4682]])\n","Procesando modelo: inceptionv3\n","Salida del modelo inceptionv3: tensor([[-0.4347,  0.2254]])\n","Salida calculada predictiva: tensor([[0.2950, 0.4867]])\n","Procesando modelo: efficientnetB0\n","Salida del modelo efficientnetB0: tensor([[-0.3660,  0.3568]])\n","Salida calculada predictiva: tensor([[0.3663, 0.6337]])\n","Predicción: MALIGNO\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"1ddsuxaKF0BgHHGTg4eT-pQGvoWZmsApw","timestamp":1714496403813},{"file_id":"1ltmoyf4kDl3DXbgrt_d8S5o7Tq-4C0AP","timestamp":1714379272264}],"authorship_tag":"ABX9TyOPF3nY+OjHwOVcWwlBNhHW"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}