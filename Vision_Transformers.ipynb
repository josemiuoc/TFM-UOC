{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1w75wm8i7kPJvrLEvL9MhYqhUOdoggyEx","timestamp":1714345376762},{"file_id":"1pU0J14ZUITHM8sZSQPLoLKg-MWtpeSWc","timestamp":1714315354890},{"file_id":"1ltmoyf4kDl3DXbgrt_d8S5o7Tq-4C0AP","timestamp":1714298908966}],"gpuType":"L4","machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import torch\n","from torch.utils.data import TensorDataset, DataLoader\n","import torchvision.transforms as transforms\n","from transformers import DeiTForImageClassification, DeiTConfig\n","from torch.optim import Adam\n","from torch.nn import CrossEntropyLoss\n","import torch.nn as nn\n","import torchvision.models as models\n","from sklearn.metrics import accuracy_score\n","import numpy as np\n","from tqdm import tqdm  # Para la barra de progreso\n","import os\n","from PIL import Image\n","from torchsummary import summary\n","import time\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, classification_report\n","import seaborn as sns"],"metadata":{"id":"W8ftcGkqFVac"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install torchsummary"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PPkuoVra8kJD","executionInfo":{"status":"ok","timestamp":1718133619280,"user_tz":-120,"elapsed":6135,"user":{"displayName":"José Miguel","userId":"06086994168164684591"}},"outputId":"10b64d2a-4f50-449f-c993-bfeb601bf0c8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qzfk-0bfRcxK","executionInfo":{"status":"ok","timestamp":1718133639086,"user_tz":-120,"elapsed":19810,"user":{"displayName":"José Miguel","userId":"06086994168164684591"}},"outputId":"6714c243-bfeb-4aaf-f8a8-a9c42dbcec7a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# @title Data Loading\n","models_list = []\n","train_losses_list = []\n","train_accuracies_list = []\n","val_losses_list = []\n","val_accuracies_list = []\n","\n","modelsdir = '/content/drive/MyDrive/combined'\n","\n","datasetdir = '/content/drive/MyDrive/cbis-ddsm'\n","X_train_1 = torch.load(datasetdir + \"/X_train_balanced.pt\")\n","y_train_1 = torch.load(datasetdir + \"/y_train_balanced.pt\")\n","X_test_1 = torch.load(datasetdir + \"/X_test.pt\")\n","y_test_1 = torch.load(datasetdir + \"/y_test.pt\")\n","\n","X_tensor = torch.load(\"/content/drive/MyDrive/output/X_oversampled.pt\")\n","y_tensor = torch.load(\"/content/drive/MyDrive/output/y_oversampled.pt\")\n","\n","from sklearn.model_selection import train_test_split\n","test_size = 0.2\n","X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_tensor, y_tensor, test_size=test_size, random_state=42)\n","\n","X_train_full = torch.cat((X_train_1, X_train_2), dim=0)\n","y_train_full = torch.cat((y_train_1, y_train_2), dim=0)\n","X_test_full = torch.cat((X_test_1, X_test_2), dim=0)\n","y_test_full = torch.cat((y_test_1, y_test_2), dim=0)\n","\n","X_train = X_train_full\n","y_train = y_train_full\n","X_test = X_test_full\n","y_test = y_test_full\n","\n","train_dataset = TensorDataset(X_train, y_train)\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, drop_last=True)\n","\n","test_dataset = TensorDataset(X_test, y_test)\n","test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, drop_last=True)\n","\n","print('X train shape : {}' .format(X_train.shape))\n","print('y train shape : {}' .format(y_train.shape))\n","print('X test shape : {}' .format(X_test.shape))\n","print('y test shape : {}' .format(y_test.shape))"],"metadata":{"id":"6-WNepldgLfN","executionInfo":{"status":"ok","timestamp":1718133708959,"user_tz":-120,"elapsed":33213,"user":{"displayName":"José Miguel","userId":"06086994168164684591"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"57a7693d-14f6-4cfe-e2b0-80bbaa9e205b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X train shape : torch.Size([9916, 1, 224, 224])\n","y train shape : torch.Size([9916])\n","X test shape : torch.Size([2060, 1, 224, 224])\n","y test shape : torch.Size([2060])\n"]}]},{"cell_type":"code","source":["# @title Early Stopping\n","## Definición de clase para el callback \"Early Stopping\" con guardado de modelo\n","class EarlyStopping:\n","    def __init__(self, path, patience=3, verbose=False, delta=0.001):\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.delta = delta\n","        self.val_loss_min = float('inf')\n","        self.path = path  # Archivo donde guardaremos el modelo\n","\n","    def __call__(self, val_loss, model):\n","        score = -val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            if self.verbose:\n","                print(f'EarlyStopping no mejoró por {self.counter} épocas')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        if val_loss < self.val_loss_min:\n","            if self.verbose:\n","                print(f'Pérdida de validación mejorada a {val_loss:.6f}. Guardando modelo...')\n","            torch.save(model, self.path)  # Guardamos el modelo a fichero\n","            self.val_loss_min = val_loss\n"],"metadata":{"cellView":"form","id":"l14q2T58uX66"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Training Function\n","def trainModel(model, train_loader, val_loader, criterion, optimizer, num_epochs, device, early_stopping, transforms):\n","    train_losses = []\n","    val_losses = []\n","    train_accuracies = []\n","    val_accuracies = []\n","\n","    for epoch in range(num_epochs):\n","        start_time = time.time()\n","        total_loss = 0\n","        correct_train = 0\n","        total_train = 0\n","\n","        model.train()\n","\n","        # Bucle de entrenamiento\n","        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n","            if transforms:\n","                transformed_images = torch.stack([transforms(image) for image in images])\n","                images, labels = transformed_images.to(device), labels.to(device)\n","            else:\n","                images, labels = images.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            total_loss += loss.item()\n","\n","            # Precisión del entrenamiento\n","            _, predicted = torch.max(outputs, 1)\n","            total_train += labels.size(0)\n","            correct_train += (predicted == labels).sum().item()\n","\n","        # Promedio de pérdida y precisión del entrenamiento\n","        avg_train_loss = total_loss / len(train_loader)\n","        train_accuracy = 100 * correct_train / total_train\n","\n","        # Guardar métricas de entrenamiento\n","        train_losses.append(avg_train_loss)\n","        train_accuracies.append(train_accuracy)\n","\n","        # Validación\n","        model.eval()  # Modo de evaluación\n","        val_loss = 0\n","        correct_val = 0\n","        total_val = 0\n","\n","\n","        with torch.no_grad():  # Sin cálculos de gradientes durante la validación\n","          for images, labels in val_loader:\n","            if transforms:\n","                transformed_images = torch.stack([transforms(image) for image in images])\n","                images, labels = transformed_images.to(device), labels.to(device)\n","            else:\n","                images, labels = images.to(device), labels.to(device)\n","\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","\n","          # Precisión de validación\n","          _, predicted = torch.max(outputs, 1)\n","          total_val += labels.size(0)\n","          correct_val += (predicted == labels).sum().item()\n","\n","        avg_val_loss = val_loss / len(val_loader)\n","        val_accuracy = 100 * correct_val / total_val\n","\n","        # Guardar métricas de validación\n","        val_losses.append(avg_val_loss)\n","        val_accuracies.append(val_accuracy)\n","\n","        end_time = time.time()  # Tiempo al final de la época\n","        epoch_duration = end_time - start_time  # Duración de la época\n","\n","        # resultados\n","        print(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {avg_train_loss:.3f}, Train Accuracy: {train_accuracy:.2f}%, Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%, Time: {epoch_duration:.2f} seconds\")\n","\n","        early_stopping(avg_val_loss, model)\n","        if early_stopping.early_stop:\n","            print(\"Early Stopping activado. Proceso detenido!\")\n","            break\n","\n","    return train_losses, train_accuracies, val_losses, val_accuracies"],"metadata":{"id":"e0KF2Gvbtggh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Métricas y gráficas\n","def metrics(model, test_loader, transforms):\n","  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","  model.eval()\n","\n","  all_preds = []\n","  all_labels = []\n","\n","  for images, labels in test_loader:\n","      if transforms:\n","          transformed_images = torch.stack([transforms(image) for image in images])\n","          images, labels = transformed_images.to(device), labels.to(device)\n","      else:\n","          images, labels = images.to(device), labels.to(device)\n","\n","      with torch.no_grad():\n","          outputs = model(images)\n","\n","      _, predicted = torch.max(outputs, 1)\n","\n","      all_preds.extend(predicted.cpu().numpy())\n","      all_labels.extend(labels.cpu().numpy())\n","\n","  conf_matrix = confusion_matrix(all_labels, all_preds)\n","\n","  plt.figure(figsize=(4, 3))\n","  sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Sin Cáncer', 'Con Cáncer'], yticklabels=['Sin Cáncer', 'Con Cáncer'])\n","  plt.xlabel('Predicciones')\n","  plt.ylabel('Verdadero')\n","  plt.title('Matriz de Confusión')\n","  plt.show()\n","\n","  accuracy = accuracy_score(all_labels, all_preds)  # Precisión global\n","  report = classification_report(all_labels, all_preds, target_names=['Sin Cáncer', 'Con Cáncer'])\n","\n","  print(f\"Precisión global: {accuracy * 100:.2f}%\")\n","  print(\"Informe y métricas de clasificación:\")\n","  print(report)\n","\n","  # Calcular métricas principales usando las listas de etiquetas y predicciones\n","  precision = precision_score(all_labels, all_preds)\n","  recall = recall_score(all_labels, all_preds)\n","  f1 = f1_score(all_labels, all_preds)\n","  accuracy = accuracy_score(all_labels, all_preds)\n","\n","  # Imprimir las métricas calculadas\n","  print(f\"Precisión: {precision:.2f}\")\n","  print(f\"Sensibilidad (Recall): {recall:.2f}\")\n","  print(f\"F1-Score: {f1:.2f}\")\n","  print(f\"Accuracy: {accuracy:.2f}\")\n","\n","  # Calcular especificidad usando la matriz de confusión\n","  true_negatives = conf_matrix[0, 0]\n","  false_positives = conf_matrix[0, 1]\n","  true_positives = conf_matrix[1, 0]\n","  false_negatives = conf_matrix[1, 1]\n","\n","  specificity = true_negatives / (true_negatives + false_positives)\n","\n","  print(f\"Especificidad: {specificity:.2f}\")\n","\n","def graphLossAccuracy(train_losses, val_losses, train_accuracies, val_accuracies):\n","  plt.plot(train_losses, label='Train Loss')\n","  plt.plot(val_losses, label='Val Loss')\n","  plt.xlabel('Epoch')\n","  plt.ylabel('Loss')\n","  plt.title('Model Loss')\n","  plt.legend(loc='upper left')\n","  plt.show()\n","\n","  plt.plot(train_accuracies, label='Train Accuracy')\n","  plt.plot(val_accuracies, label='Val Accuracy')\n","  plt.xlabel('Epoch')\n","  plt.ylabel('Accuracy')\n","  plt.title('Model Accuracy')\n","  plt.legend(loc='upper left')\n","  plt.show()"],"metadata":{"cellView":"form","id":"rNGuevKWug9B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install timm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yjjkv-zJ7qH8","executionInfo":{"status":"ok","timestamp":1718133768854,"user_tz":-120,"elapsed":59900,"user":{"displayName":"José Miguel","userId":"06086994168164684591"}},"outputId":"219443ee-b714-4e87-e9ad-2de035f22544"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting timm\n","  Downloading timm-1.0.3-py3-none-any.whl (2.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.3.0+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.18.0+cu121)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.23.2)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.14.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2023.6.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.12.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.4)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->timm)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->timm)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->timm)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->timm)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->timm)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->timm)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch->timm)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->timm)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->timm)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch->timm)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch->timm)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->timm)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.25.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.6.2)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, timm\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 timm-1.0.3\n"]}]},{"cell_type":"code","source":["from timm import create_model\n","\n","transform = transforms.Compose([\n","    transforms.CenterCrop(224),\n","    transforms.Lambda(lambda x: x.repeat(3, 1, 1)),  # Repetir el canal de escala de grises para obtener 3 canales\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","model = create_model('deit_base_patch16_224', pretrained=True, num_classes=2)\n","model = model.cuda()\n","\n","optimizer = Adam(model.parameters(), lr=0.001)\n","criterion = nn.CrossEntropyLoss()\n","\n","fichModelo = modelsdir + '/Deit.pth'\n","eaStop = EarlyStopping(fichModelo, patience=15, verbose=True, delta=0.001)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","epochs = 30\n","\n","train_loss, train_accu, val_loss, val_accu = trainModel(model,train_loader,test_loader,criterion,optimizer,epochs,device,eaStop,transform)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"zOqzUpeItFiq","executionInfo":{"status":"error","timestamp":1718136647182,"user_tz":-120,"elapsed":2855961,"user":{"displayName":"José Miguel","userId":"06086994168164684591"}},"outputId":"cdcb00f1-f272-453d-e84a-891c28341130"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 1/30: 100%|██████████| 619/619 [02:22<00:00,  4.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/30], Train Loss: 0.710, Train Accuracy: 50.23%, Val Loss: 0.6923, Val Accuracy: 56.25%, Time: 152.32 seconds\n","Pérdida de validación mejorada a 0.692283. Guardando modelo...\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/30: 100%|██████████| 619/619 [02:25<00:00,  4.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [2/30], Train Loss: 0.694, Train Accuracy: 51.04%, Val Loss: 0.6911, Val Accuracy: 56.25%, Time: 155.80 seconds\n","Pérdida de validación mejorada a 0.691135. Guardando modelo...\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/30: 100%|██████████| 619/619 [02:28<00:00,  4.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [3/30], Train Loss: 0.693, Train Accuracy: 52.01%, Val Loss: 0.6962, Val Accuracy: 43.75%, Time: 158.78 seconds\n","EarlyStopping no mejoró por 1 épocas\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/30: 100%|██████████| 619/619 [02:28<00:00,  4.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [4/30], Train Loss: 0.696, Train Accuracy: 51.33%, Val Loss: 0.6937, Val Accuracy: 43.75%, Time: 158.79 seconds\n","EarlyStopping no mejoró por 2 épocas\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/30: 100%|██████████| 619/619 [02:28<00:00,  4.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [5/30], Train Loss: 0.694, Train Accuracy: 51.23%, Val Loss: 0.6958, Val Accuracy: 43.75%, Time: 158.85 seconds\n","EarlyStopping no mejoró por 3 épocas\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6/30: 100%|██████████| 619/619 [02:28<00:00,  4.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [6/30], Train Loss: 0.692, Train Accuracy: 52.36%, Val Loss: 0.6922, Val Accuracy: 68.75%, Time: 158.83 seconds\n","EarlyStopping no mejoró por 4 épocas\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7/30: 100%|██████████| 619/619 [02:28<00:00,  4.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [7/30], Train Loss: 0.692, Train Accuracy: 52.25%, Val Loss: 0.6915, Val Accuracy: 68.75%, Time: 158.75 seconds\n","EarlyStopping no mejoró por 5 épocas\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8/30: 100%|██████████| 619/619 [02:28<00:00,  4.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [8/30], Train Loss: 0.690, Train Accuracy: 53.07%, Val Loss: 0.7019, Val Accuracy: 43.75%, Time: 158.79 seconds\n","EarlyStopping no mejoró por 6 épocas\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9/30: 100%|██████████| 619/619 [02:28<00:00,  4.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [9/30], Train Loss: 0.690, Train Accuracy: 52.38%, Val Loss: 0.6878, Val Accuracy: 68.75%, Time: 158.75 seconds\n","Pérdida de validación mejorada a 0.687801. Guardando modelo...\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10/30: 100%|██████████| 619/619 [02:28<00:00,  4.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [10/30], Train Loss: 0.691, Train Accuracy: 52.78%, Val Loss: 0.6936, Val Accuracy: 68.75%, Time: 158.74 seconds\n","EarlyStopping no mejoró por 1 épocas\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 11/30: 100%|██████████| 619/619 [02:28<00:00,  4.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [11/30], Train Loss: 0.689, Train Accuracy: 53.16%, Val Loss: 0.7216, Val Accuracy: 37.50%, Time: 158.75 seconds\n","EarlyStopping no mejoró por 2 épocas\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 12/30: 100%|██████████| 619/619 [02:28<00:00,  4.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [12/30], Train Loss: 0.688, Train Accuracy: 53.06%, Val Loss: 0.6930, Val Accuracy: 62.50%, Time: 158.75 seconds\n","EarlyStopping no mejoró por 3 épocas\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 13/30: 100%|██████████| 619/619 [02:28<00:00,  4.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [13/30], Train Loss: 0.689, Train Accuracy: 52.59%, Val Loss: 0.6915, Val Accuracy: 62.50%, Time: 158.75 seconds\n","EarlyStopping no mejoró por 4 épocas\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 14/30: 100%|██████████| 619/619 [02:28<00:00,  4.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [14/30], Train Loss: 0.688, Train Accuracy: 53.00%, Val Loss: 0.6983, Val Accuracy: 68.75%, Time: 158.73 seconds\n","EarlyStopping no mejoró por 5 épocas\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 15/30: 100%|██████████| 619/619 [02:28<00:00,  4.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [15/30], Train Loss: 0.686, Train Accuracy: 53.54%, Val Loss: 0.6999, Val Accuracy: 56.25%, Time: 158.35 seconds\n","EarlyStopping no mejoró por 6 épocas\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 16/30: 100%|██████████| 619/619 [02:28<00:00,  4.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [16/30], Train Loss: 0.688, Train Accuracy: 52.78%, Val Loss: 0.6920, Val Accuracy: 68.75%, Time: 158.33 seconds\n","EarlyStopping no mejoró por 7 épocas\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 17/30: 100%|██████████| 619/619 [02:28<00:00,  4.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [17/30], Train Loss: 0.693, Train Accuracy: 51.74%, Val Loss: 0.7295, Val Accuracy: 56.25%, Time: 158.39 seconds\n","EarlyStopping no mejoró por 8 épocas\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 18/30:  99%|█████████▊| 610/619 [02:26<00:02,  4.17it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-b9f9f708c405>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meaStop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-6-f74bc0742673>\u001b[0m in \u001b[0;36mtrainModel\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, num_epochs, device, early_stopping, transforms)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# Precisión del entrenamiento\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["models_list.append(\"DeiT\");\n","train_losses_list.append(train_loss)\n","train_accuracies_list.append(train_accu)\n","val_losses_list.append(val_loss)\n","val_accuracies_list.append(val_accu)\n","\n","graphLossAccuracy(train_loss, val_loss, train_accu, val_accu)\n","\n","metrics(model, test_loader, transform)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"EGqie4Ii94Rd","executionInfo":{"status":"error","timestamp":1718136649428,"user_tz":-120,"elapsed":371,"user":{"displayName":"José Miguel","userId":"06086994168164684591"}},"outputId":"048ea7e7-363c-4ec1-e295-4a8994ed40e8"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'train_loss' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-4c25e23c2cff>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodels_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DeiT\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_losses_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_accuracies_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_accu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval_losses_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_accuracies_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_accu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_loss' is not defined"]}]},{"cell_type":"code","source":["# Configuración del dispositivo\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","X_train = torch.cat([X_train, X_train, X_train], dim=1)\n","X_test = torch.cat([X_test, X_test, X_test], dim=1)\n","\n","train_dataset = TensorDataset(X_train, y_train)\n","test_dataset = TensorDataset(X_test, y_test)\n","\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, drop_last=True)\n","test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, drop_last=True)\n","\n","# Cargar el modelo ViT preentrenado\n","model = models.vit_b_16(pretrained=True)\n","\n","# Adaptar capa final a las 2 salidas necesarias\n","num_features = model.heads.head.in_features\n","model.heads = nn.Linear(num_features, 2)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","optimizer = Adam(model.parameters(), lr=0.001)\n","criterion = CrossEntropyLoss()\n","\n","import time\n","from tqdm import tqdm\n","\n","# Entrenamiento básico\n","num_epochs = 5\n","for epoch in range(num_epochs):\n","    model.train()\n","\n","    start_time = time.time()\n","\n","    total_loss = 0.0\n","    correct_predictions = 0\n","    total_predictions = 0\n","\n","    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}', position=0, leave=True)\n","\n","    for images, labels in progress_bar:\n","        images, labels = images.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item() * images.size(0)\n","        _, predicted = torch.max(outputs, 1)\n","        correct_predictions += (predicted == labels).sum().item()\n","        total_predictions += labels.size(0)\n","\n","        progress_bar.set_postfix({'Loss': loss.item()})\n","\n","    epoch_loss = total_loss / len(train_loader.dataset)\n","    epoch_accuracy = correct_predictions / total_predictions\n","\n","    progress_bar.close()\n","\n","    epoch_time = time.time() - start_time\n","\n","    print(f\"Epoch {epoch + 1}/{num_epochs} - Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}, Time: {epoch_time:.2f} seconds\")"],"metadata":{"id":"TtJ6D0Rk7lQD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluación\n","model.eval()\n","predictions = []\n","true_labels = []\n","\n","with torch.no_grad():\n","    for images, labels in tqdm(test_loader, desc='Evaluation', position=0, leave=True):\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs, 1)\n","        predictions.extend(predicted.cpu().numpy())\n","        true_labels.extend(labels.cpu().numpy())\n","\n","accuracy = accuracy_score(true_labels, predictions)\n","print(\"Test Accuracy:\", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2cD8alTumAqv","executionInfo":{"status":"ok","timestamp":1715513882407,"user_tz":-120,"elapsed":5261,"user":{"displayName":"José Miguel Blázquez Soriano","userId":"09239837395905426031"}},"outputId":"c09527c0-5380-4b55-e69d-114df30cbb88"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Evaluation: 100%|██████████| 26/26 [00:05<00:00,  5.07it/s]"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 0.6346153846153846\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class PatchEmbedding(nn.Module):\n","    def __init__(self, img_size, patch_size, in_channels, embed_dim):\n","        super(PatchEmbedding, self).__init__()\n","        self.patch_size = patch_size\n","        self.num_patches = (img_size // patch_size) ** 2\n","        self.projection = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n","\n","    def forward(self, x):\n","        x = self.projection(x)\n","        x = x.flatten(2)  # Aplanar en el eje de las características\n","        x = x.transpose(1, 2)  # Transponer para obtener la forma [batch, num_patches, embed_dim]\n","        return x\n","\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, embed_dim, num_patches):\n","        super(PositionalEncoding, self).__init__()\n","        # Crear embeddings posicionales sin entrenar\n","        self.position_embeddings = nn.Parameter(torch.zeros(1, num_patches + 1, embed_dim))\n","\n","    def forward(self, x):\n","        return x + self.position_embeddings[:, :x.size(1)]  # Ajustar el tamaño\n","\n","class MultiHeadAttention(nn.Module):\n","    def __init__(self, embed_dim, num_heads):\n","        super(MultiHeadAttention, self).__init__()\n","        self.attention = nn.MultiheadAttention(embed_dim, num_heads)\n","\n","    def forward(self, x):\n","        # Self-attention requiere que el tensor tenga la forma [num_patches, batch, embed_dim]\n","        x = x.transpose(0, 1)  # Transponer para la atención\n","        x, _ = self.attention(x, x, x)\n","        return x.transpose(0, 1)  # Volver a la forma original\n","\n","class FeedForward(nn.Module):\n","    def __init__(self, embed_dim, hidden_dim, dropout=0.1):\n","        super(FeedForward, self).__init__()\n","        self.linear1 = nn.Linear(embed_dim, hidden_dim)\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(dropout)\n","        self.linear2 = nn.Linear(hidden_dim, embed_dim)\n","\n","    def forward(self, x):\n","        x = self.linear1(x)\n","        x = self.relu(x)\n","        x = self.dropout(x)\n","        return self.linear2(x)\n","\n","class TransformerBlock(nn.Module):\n","    def __init__(self, embed_dim, num_heads, hidden_dim, dropout=0.1):\n","        super(TransformerBlock, self).__init__()\n","        self.attention = MultiHeadAttention(embed_dim, num_heads)\n","        self.norm1 = nn.LayerNorm(embed_dim)\n","        self.feedforward = FeedForward(embed_dim, hidden_dim, dropout)\n","        self.norm2 = nn.LayerNorm(embed_dim)\n","\n","    def forward(self, x):\n","        # Bloque de atención con conexión residual\n","        attn_output = self.attention(x)\n","        x = self.norm1(x + attn_output)\n","\n","        # Bloque de feedforward con conexión residual\n","        ff_output = self.feedforward(x)\n","        return self.norm2(x + ff_output)\n","\n","class VisionTransformer(nn.Module):\n","    def __init__(self, img_size, patch_size, in_channels, embed_dim, num_heads, hidden_dim, num_classes, num_layers):\n","        super(VisionTransformer, self).__init__()\n","        # Embeddings de parches\n","        self.patch_embedding = PatchEmbedding(img_size, patch_size, in_channels, embed_dim)\n","\n","        # Positional encoding\n","        num_patches = self.patch_embedding.num_patches\n","        self.positional_encoding = PositionalEncoding(embed_dim, num_patches)\n","\n","        # Bloques del Transformer\n","        self.blocks = nn.ModuleList([\n","            TransformerBlock(embed_dim, num_heads, hidden_dim) for _ in range(num_layers)\n","        ])\n","\n","        # Clasificación\n","        self.norm = nn.LayerNorm(embed_dim)\n","        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))  # Token de clasificación\n","        self.linear = nn.Linear(embed_dim, num_classes)\n","\n","    def forward(self, x):\n","        # Obtener embeddings de parches\n","        x = self.patch_embedding(x)\n","\n","        # Añadir positional encoding y token de clasificación\n","        batch_size = x.shape[0]\n","        cls_token = self.cls_token.repeat(batch_size, 1, 1)\n","        x = torch.cat([cls_token, x], dim=1)  # Agregar token de clasificación\n","        x = self.positional_encoding(x)\n","\n","        # Pasar por los bloques del Transformer\n","        for block in self.blocks:\n","            x = block(x)\n","\n","        # Usar solo el token de clasificación para la salida final\n","        x = self.norm(x[:, 0])  # Seleccionar el primer token\n","        return self.linear(x)"],"metadata":{"id":"112islhfeHGG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Configuración del modelo\n","img_size = 224\n","patch_size = 16  # Tamaño de los parches\n","embed_dim = 768  # Dimensión de los embeddings\n","num_heads = 12\n","hidden_dim = 3072  # Dimensión de la red feedforward\n","num_layers = 12  # Número de bloques del Transformer\n","num_classes = 2\n","\n","vit = VisionTransformer(img_size, patch_size, 1, embed_dim, num_heads, hidden_dim, num_classes, num_layers)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","vit.to(device)"],"metadata":{"id":"v7S06LHWeXIm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717527201396,"user_tz":-120,"elapsed":852,"user":{"displayName":"José Miguel","userId":"06086994168164684591"}},"outputId":"eba62adf-7be1-4387-81bd-1ddc42a341a6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["VisionTransformer(\n","  (patch_embedding): PatchEmbedding(\n","    (projection): Conv2d(1, 768, kernel_size=(16, 16), stride=(16, 16))\n","  )\n","  (positional_encoding): PositionalEncoding()\n","  (blocks): ModuleList(\n","    (0-11): 12 x TransformerBlock(\n","      (attention): MultiHeadAttention(\n","        (attention): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (feedforward): FeedForward(\n","        (linear1): Linear(in_features=768, out_features=3072, bias=True)\n","        (relu): ReLU()\n","        (dropout): Dropout(p=0.1, inplace=False)\n","        (linear2): Linear(in_features=3072, out_features=768, bias=True)\n","      )\n","      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  (linear): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.metrics import accuracy_score\n","from tqdm import tqdm\n","import time\n","\n","# Función de entrenamiento\n","def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10, device='cuda'):\n","    best_model_wts = model.state_dict()\n","    best_val_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        running_train_loss = 0.0\n","        correct_train_predictions = 0\n","        total_train_predictions = 0\n","\n","        progress_bar = tqdm(total=len(train_loader), desc=f'Epoch {epoch+1}/{num_epochs}', position=0, leave=True)\n","\n","        start_time = time.time()\n","\n","        for inputs, labels in train_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_train_loss += loss.item() * inputs.size(0)\n","\n","            _, predicted = torch.max(outputs, 1)\n","            correct_train_predictions += (predicted == labels).sum().item()\n","            total_train_predictions += labels.size(0)\n","\n","            progress_bar.set_postfix({'Train Loss': loss.item()})\n","            progress_bar.update()\n","\n","        progress_bar.close()\n","\n","        epoch_train_loss = running_train_loss / len(train_loader.dataset)\n","        train_accuracy = correct_train_predictions / total_train_predictions\n","\n","        val_accuracy = evaluate_model(model, val_loader, device)\n","\n","        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_train_loss:.4f}, Train Acc: {train_accuracy:.4f}, Val Acc: {val_accuracy:.4f}')\n","\n","        if val_accuracy > best_val_acc:\n","            best_val_acc = val_accuracy\n","            best_model_wts = model.state_dict()\n","\n","        epoch_time = time.time() - start_time\n","        print(f\"Epoch {epoch+1}/{num_epochs}, Time: {epoch_time:.2f} seconds\")\n","\n","    model.load_state_dict(best_model_wts)\n","    return model\n","\n","def evaluate_model(model, data_loader, device='cuda'):\n","    model.eval()  # Poner el modelo en modo de evaluación\n","    all_preds = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for inputs, labels in data_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            _, preds = torch.max(outputs, 1)\n","            all_preds.extend(preds.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","\n","    acc = accuracy_score(all_labels, all_preds)\n","    return acc\n","\n","train_dataset = TensorDataset(X_train, y_train)\n","test_dataset = TensorDataset(X_test, y_test)\n","\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","val_loader = DataLoader(test_dataset, batch_size=16)\n","\n","learning_rate = 0.001\n","num_epochs = 10\n","batch_size = 32\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(vit.parameters(), lr=learning_rate)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","trained_model = train_model(vit, criterion, optimizer, train_loader, val_loader, num_epochs, device)\n","\n","test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size)\n","test_acc = evaluate_model(trained_model, test_loader, device)\n","print(\"Test Accuracy:\", test_acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":558},"id":"2dHMT1Rcm5yW","executionInfo":{"status":"error","timestamp":1717528053779,"user_tz":-120,"elapsed":819520,"user":{"displayName":"José Miguel","userId":"06086994168164684591"}},"outputId":"de30695a-4ba7-4a7d-f0db-cc72ca015067"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 1/10: 100%|██████████| 620/620 [02:43<00:00,  3.78it/s, Train Loss=0.75]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Train Loss: 0.7354, Train Acc: 0.4924, Val Acc: 0.5316\n","Epoch 1/10, Time: 175.11 seconds\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/10: 100%|██████████| 620/620 [02:44<00:00,  3.77it/s, Train Loss=0.684]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/10, Train Loss: 0.6960, Train Acc: 0.4936, Val Acc: 0.5316\n","Epoch 2/10, Time: 175.77 seconds\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/10: 100%|██████████| 620/620 [02:44<00:00,  3.77it/s, Train Loss=0.697]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/10, Train Loss: 0.6941, Train Acc: 0.4930, Val Acc: 0.5316\n","Epoch 3/10, Time: 175.78 seconds\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/10: 100%|██████████| 620/620 [02:44<00:00,  3.77it/s, Train Loss=0.691]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4/10, Train Loss: 0.6935, Train Acc: 0.4864, Val Acc: 0.5316\n","Epoch 4/10, Time: 175.77 seconds\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/10:  70%|███████   | 435/620 [01:55<00:49,  3.76it/s, Train Loss=0.694]"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-67ba8ebf14cd>\u001b[0m in \u001b[0;36m<cell line: 106>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;31m# Entrenar el modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;31m# Evaluar el modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-67ba8ebf14cd>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, train_loader, val_loader, num_epochs, device)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mrunning_train_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;31m# Calcular precisión en entrenamiento\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.metrics import accuracy_score\n","from tqdm import tqdm\n","\n","# Función de entrenamiento\n","def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10, device='cuda'):\n","    best_model_wts = model.state_dict()\n","    best_val_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        running_train_loss = 0.0\n","        correct_train_predictions = 0\n","        total_train_predictions = 0\n","\n","        progress_bar = tqdm(total=len(train_loader), desc=f'Epoch {epoch+1}/{num_epochs}', position=0, leave=True)\n","\n","        for inputs, labels in train_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_train_loss += loss.item() * inputs.size(0)\n","\n","            _, predicted = torch.max(outputs, 1)\n","            correct_train_predictions += (predicted == labels).sum().item()\n","            total_train_predictions += labels.size(0)\n","\n","            progress_bar.set_postfix({'Train Loss': loss.item()})\n","            progress_bar.update()\n","\n","        progress_bar.close()\n","\n","        epoch_train_loss = running_train_loss / len(train_loader.dataset)\n","        train_accuracy = correct_train_predictions / total_train_predictions\n","        val_accuracy = evaluate_model(model, val_loader, device)\n","\n","        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_train_loss:.4f}, Train Acc: {train_accuracy:.4f}, Val Acc: {val_accuracy:.4f}')\n","\n","        if val_accuracy > best_val_acc:\n","            best_val_acc = val_accuracy\n","            best_model_wts = model.state_dict()\n","\n","    model.load_state_dict(best_model_wts)\n","    return model\n","\n","# Función de evaluación\n","def evaluate_model(model, data_loader, device='cuda'):\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for inputs, labels in data_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            _, preds = torch.max(outputs, 1)\n","            all_preds.extend(preds.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","\n","    # Calcular precisión\n","    acc = accuracy_score(all_labels, all_preds)\n","    return acc\n","\n","train_dataset = TensorDataset(X_train, y_train)\n","val_dataset = TensorDataset(X_test, y_test)\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","\n","learning_rate = 0.001\n","num_epochs = 10\n","batch_size = 32\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(vit.parameters(), lr=learning_rate)\n","\n","# Entrenar el modelo\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","trained_model = train_model(vit, criterion, optimizer, train_loader, val_loader, num_epochs, device)\n","\n","# Evaluar el modelo\n","test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size)\n","test_acc = evaluate_model(trained_model, test_loader, device)\n","print(\"Test Accuracy:\", test_acc)\n"],"metadata":{"id":"3Ldn1NfefseN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.metrics import accuracy_score\n","from tqdm import tqdm\n","import time\n","\n","# Función de entrenamiento\n","def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10, device='cuda'):\n","    best_model_wts = model.state_dict()\n","    best_val_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        running_train_loss = 0.0\n","        correct_train_predictions = 0\n","        total_train_predictions = 0\n","\n","        progress_bar = tqdm(total=len(train_loader), desc=f'Epoch {epoch+1}/{num_epochs}', position=0, leave=True)\n","\n","        start_time = time.time()\n","\n","        # Bucle de entrenamiento\n","        for inputs, labels in train_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_train_loss += loss.item() * inputs.size(0)\n","\n","            _, predicted = torch.max(outputs, 1)\n","            correct_train_predictions += (predicted == labels).sum().item()\n","            total_train_predictions += labels.size(0)\n","\n","            progress_bar.set_postfix({'Train Loss': loss.item()})\n","            progress_bar.update()\n","\n","        progress_bar.close()\n","\n","        epoch_train_loss = running_train_loss / len(train_loader.dataset)\n","        train_accuracy = correct_train_predictions / total_train_predictions\n","\n","        val_accuracy = evaluate_model(model, val_loader, device)\n","\n","        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_train_loss:.4f}, Train Acc: {train_accuracy:.4f}, Val Acc: {val_accuracy:.4f}')\n","\n","        if val_accuracy > best_val_acc:\n","            best_val_acc = val_accuracy\n","            best_model_wts = model.state_dict()\n","\n","        epoch_time = time.time() - start_time\n","        print(f\"Epoch {epoch+1}/{num_epochs}, Time: {epoch_time:.2f} seconds\")\n","\n","    model.load_state_dict(best_model_wts)\n","    return model\n","\n","# Función de evaluación\n","def evaluate_model(model, data_loader, device='cuda'):\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for inputs, labels in data_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            _, preds = torch.max(outputs, 1)\n","            all_preds.extend(preds.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","\n","    acc = accuracy_score(all_labels, all_preds)\n","    return acc\n","\n","train_dataset = TensorDataset(X_train, y_train)\n","val_dataset = TensorDataset(X_test, y_test)\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","\n","learning_rate = 0.001\n","num_epochs = 10\n","batch_size = 32\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(vit.parameters(), lr=learning_rate)\n","\n","# Entrenar\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","trained_model = train_model(vit, criterion, optimizer, train_loader, val_loader, num_epochs, device)\n","\n","# Evaluar\n","test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size)\n","test_acc = evaluate_model(trained_model, test_loader, device)\n","print(\"Test Accuracy:\", test_acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"oziFEMFTmrJo","executionInfo":{"status":"error","timestamp":1715514033212,"user_tz":-120,"elapsed":363,"user":{"displayName":"José Miguel Blázquez Soriano","userId":"09239837395905426031"}},"outputId":"3db0d665-6352-43a5-897a-284ae80ac909"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'batch_size' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-8650deb2d21c>\u001b[0m in \u001b[0;36m<cell line: 93>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;31m# Crear DataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'batch_size' is not defined"]}]},{"cell_type":"code","source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","def calculate_metrics_from_confusion_matrix(cm):\n","    # Calcular métricas\n","    tn, fp, fn, tp = cm.ravel()\n","    accuracy = (tp + tn) / (tp + tn + fp + fn)\n","    precision = tp / (tp + fp)\n","    recall = tp / (tp + fn)\n","    specificity = tn / (tn + fp)\n","    f1_score = 2 * (precision * recall) / (precision + recall)\n","\n","    # Mostrar métricas\n","    print(f\"Accuracy: {accuracy:.4f}\")\n","    print(f\"Precision: {precision:.4f}\")\n","    print(f\"Recall (Sensitivity): {recall:.4f}\")\n","    print(f\"Specificity: {specificity:.4f}\")\n","    print(f\"F1 Score: {f1_score:.4f}\")\n","\n","# Función para mostrar la matriz de confusión y las métricas con Seaborn\n","def show_metrics_with_seaborn(model, X_test, y_test):\n","    model.eval()  # Poner el modelo en modo de evaluación\n","    with torch.no_grad():\n","        outputs = model(X_test)\n","        _, predicted = torch.max(outputs, 1)\n","\n","    # Calcular y mostrar la matriz de confusión\n","    cm = confusion_matrix(y_test.cpu().numpy(), predicted.cpu().numpy())\n","    plt.figure(figsize=(6, 4))\n","    sns.set(font_scale=1.1)\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=range(num_classes), yticklabels=range(num_classes))\n","    plt.xlabel('Predicted Label')\n","    plt.ylabel('True Label')\n","    plt.title('Confusion Matrix')\n","    plt.show()\n","\n","    # Calcular métricas a partir de la matriz de confusión\n","    calculate_metrics_from_confusion_matrix(cm)\n","\n","# Evaluar el modelo en conjunto de prueba\n","test_acc = evaluate_model(trained_model, X_test, y_test)\n","print(\"Test Accuracy:\", test_acc)\n","\n","X_test = X_test.to(device)\n","y_test = y_test.to(device)\n","# Mostrar matriz de confusión y métricas con Seaborn\n","show_metrics_with_seaborn(trained_model, X_test, y_test)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":526},"id":"Ht3nBl08kFrf","executionInfo":{"status":"ok","timestamp":1715382362554,"user_tz":-120,"elapsed":23079,"user":{"displayName":"José Miguel Blázquez Soriano","userId":"09239837395905426031"}},"outputId":"83507412-ebab-4667-814e-c23481cb2b61"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy: 0.7790585975024016\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 600x400 with 2 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.7791\n","Precision: 0.7791\n","Recall (Sensitivity): 1.0000\n","Specificity: 0.0000\n","F1 Score: 0.8758\n"]}]}]}